# =============================================================================
# Adizon Ingestion Worker - Docker Compose
# Compute-intensive microservice for document processing & graph extraction
# =============================================================================
#
# Network Mode: Host
# - Uses host network for direct access to local services (Ollama, etc.)
# - No external network dependencies required
#
# Usage:
#   docker-compose up -d --build
#
# =============================================================================

services:
  adizon-worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: adizon-worker
    restart: unless-stopped
    network_mode: "host"

    environment:
      # -----------------------------------------------------------------------
      # PostgreSQL + pgvector
      # -----------------------------------------------------------------------
      - POSTGRES_HOST=${POSTGRES_HOST:-postgres}
      - POSTGRES_PORT=${POSTGRES_PORT:-5432}
      - POSTGRES_DB=${POSTGRES_DB:-knowledge_core}
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}

      # -----------------------------------------------------------------------
      # Neo4j
      # -----------------------------------------------------------------------
      - NEO4J_URI=${NEO4J_URI:-bolt://neo4j:7687}
      - NEO4J_USER=${NEO4J_USER:-neo4j}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}

      # -----------------------------------------------------------------------
      # MinIO / S3
      # -----------------------------------------------------------------------
      - MINIO_ENDPOINT=${MINIO_ENDPOINT:-minio:9000}
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY}
      - MINIO_BUCKET_NAME=${MINIO_BUCKET_NAME:-knowledge-documents}
      - MINIO_SECURE=${MINIO_SECURE:-false}

      # -----------------------------------------------------------------------
      # AI API (Trooper LLM Server)
      # -----------------------------------------------------------------------
      - EMBEDDING_API_URL=${EMBEDDING_API_URL}
      - EMBEDDING_API_KEY=${EMBEDDING_API_KEY}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-jina/jina-embeddings-v2-base-de}
      - LLM_MODEL_NAME=${LLM_MODEL_NAME:-adizon-ministral}

      # -----------------------------------------------------------------------
      # Ontology Configuration
      # -----------------------------------------------------------------------
      - ONTOLOGY_PATH=${ONTOLOGY_PATH:-config/ontology_voltage.yaml}

      # -----------------------------------------------------------------------
      # Backend Callback URL (deprecated in v1.1.0 - use callback_url in request)
      # -----------------------------------------------------------------------
      - BACKEND_URL=${BACKEND_URL:-http://localhost:8000}

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
